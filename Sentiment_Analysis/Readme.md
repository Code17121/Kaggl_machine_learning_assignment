# ğŸ¬ Movie Review Sentiment Prediction â€“ Machine Learning Assignment

## ğŸ“Œ Project Overview

This project focuses on predicting the sentiment of movie reviews using Machine Learning techniques. The task is a multi-class classification problem, where each review is classified as negative (0), neutral (1), or positive (2).

The assignment is conducted on the Kaggle platform, and model performance is evaluated on the leaderboard based on prediction accuracy. Only submissions that appear on the leaderboard and cross the cutoff score are considered for grading.

A complete Kaggle Notebook and a video walkthrough explaining the methodology and insights are provided as part of the submission.

## ğŸ Competition Details

- **Platform:** Kaggle
- **Start Date:** Dec 2, 2025
- **End Date:** Dec 11, 2025
- **Evaluation Metric:** Accuracy
- **Competition Link:** https://www.kaggle.com/t/bdfe59603f7a49819e1888c5b35cadb5

## ğŸ“‚ Dataset Description

The dataset is provided by a movie review platform aiming to analyze user sentiments.

### Files Provided

| File Name | Description |
|-----------|-------------|
| `train.csv` | Training dataset containing features and target variable (sentiment) |
| `test.csv` | Test dataset with target column hidden |
| `sample_submission.csv` | Sample submission file in the correct format |

### ğŸ”‘ Feature Description

| Column Name | Description |
|-------------|-------------|
| `id` | Unique identifier |
| `phrase` | Movie review text |
| `feature_1` | Engineered feature derived from the review |
| `feature_2` | Engineered feature derived from the review |
| `feature_3` | Engineered feature derived from the review |
| `sentiment` | Target variable (0 = Negative, 1 = Neutral, 2 = Positive) |

## ğŸ§ª Project Workflow

The notebook strictly follows the peer-review rubrics provided for evaluation.

### 1ï¸âƒ£ Data Understanding
- Identified and explicitly stated data types of all columns
- Examined text and numerical feature distributions

### 2ï¸âƒ£ Exploratory Data Analysis (EDA)
- Generated descriptive statistics for numerical features (min, max, mean, median)
- Analyzed sentiment class distribution

### 3ï¸âƒ£ Data Cleaning
- Identified and handled missing values
- Checked for duplicate records and removed them where applicable
- Detected outliers in numerical features and justified retention or removal

### 4ï¸âƒ£ Data Visualization
At least three meaningful visualizations were created, including:
- Sentiment class distribution
- Feature distributions
- Relationship between engineered features and sentiment

Each visualization includes clear insights.

### 5ï¸âƒ£ Feature Engineering
- Text preprocessing applied to review phrases
- Numerical features scaled where required
- Categorical variables encoded using appropriate techniques
- Clear justification provided for scaling and encoding choices

## ğŸ¤– Model Building

The following **8 Machine Learning models** were trained and evaluated:

1. LinearSVC
2. Logistic Regression
3. Complement Naive Bayes
4. Multinomial Naive Bayes
5. SGDClassifier
6. XGBoost Classifier
7. Random Forest Classifier
8. Gaussian Naive Bayes

This satisfies the requirement of training at least 7 different models.

### Model Performance Comparison

| Model | Accuracy |
|-------|----------|
| LinearSVC | 0.6300 |
| Logistic Regression | 0.6293 |
| Complement Naive Bayes | 0.6250 |
| Multinomial Naive Bayes | 0.6200 |
| SGDClassifier | 0.6121 |
| XGBoost Classifier | 0.5500 |
| Random Forest Classifier | 0.5350 |
| Gaussian Naive Bayes | 0.4871 |

## âš™ï¸ Hyperparameter Tuning

Hyperparameter tuning was performed on 3 models using:
- GridSearchCV
- RandomizedSearchCV

**Tuned models include:**
- LinearSVC
- Logistic Regression
- Multinomial Naive Bayes

## ğŸ“Š Model Evaluation & Comparison

- Models evaluated using validation accuracy
- Performance of all models compared on a validation set
- LinearSVC achieved the highest accuracy (0.6300)
- Best-performing model selected based on accuracy and generalization ability

## ğŸ“ˆ Submission Format

Predictions were generated for the test dataset in the following format:

```csv
id,sentiment
0,1
1,2
2,0
...
```

## ğŸ¥ Video Walkthrough

A video walkthrough (8â€“12 minutes) explaining the notebook, models, and insights is available below:

ğŸ”— **Video URL:** https://drive.google.com/file/d/1WC5ZSeRilobxX64-rTGQ3Qh1m6fqo7Kk/view?usp=sharing

> Ensure access is set to "Anyone with the link â€“ Viewer"

## ğŸ“ Repository Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ sample_submission.csv
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ Movie_Review_Sentiment_Prediction.ipynb
â”œâ”€â”€ submission/
â”‚   â””â”€â”€ submission.csv
â””â”€â”€ README.md
```

## ğŸ§‘â€ğŸ’» Tools & Technologies Used

- Python
- Pandas, NumPy
- Matplotlib, Seaborn
- Scikit-learn
- Natural Language Processing (NLP) techniques
- Kaggle Notebooks

## ğŸ“ Notes

- Kaggle submission above cutoff score is mandatory for marks
- Completion of 5 peer reviews is required post-submission
- Code emphasizes readability, modularity, and reproducibility
- Markdown explanations clearly justify modeling decisions

## âœ… Conclusion

This project demonstrates a complete end-to-end Machine Learning and NLP classification workflow, covering text preprocessing, feature engineering, model training, hyperparameter tuning, and leaderboard-based evaluation on a real-world sentiment analysis task.
